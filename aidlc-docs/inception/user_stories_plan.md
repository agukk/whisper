# 音声入力アプリ - ユーザーストーリー作成計画

## 概要

音声入力アプリのユーザーストーリーを作成するための計画です。各ステップを順番に実行し、レビューと承認を得ながら進めます。

---

## ステップ

### ステップ 1: アプリの目的とスコープの明確化

- [x] アプリの目的、ターゲットユーザー、主要な機能の範囲を定義する

[Question] 以下の点について教えてください：
1. このアプリの主な目的は何ですか？（例：会議の議事録作成、メモの音声入力、音声メッセージの文字起こし など）
2. ターゲットユーザーは誰ですか？（例：ビジネスユーザー、一般消費者、学生 など）
3. 対応するプラットフォームは何ですか？（例：Web アプリ、iOS、Android、デスクトップ など）
4. 対応する言語は何ですか？（例：日本語のみ、日本語と英語、多言語対応 など）
5. 音声認識エンジンは何を使用しますか？（例：OpenAI Whisper、Google Speech-to-Text、独自エンジン など）

[Answer]
1. 主に音声メッセージの文字起こしを行うのが主な目的です。
2. ターゲットユーザーは特に指定はないです。
3. ターゲットのプラットフォームは、デスクトップになります。 具体的なアプリとして、wispr flow みたいなものを作成したいなと思っています。
4. 対応する言語は、日本語と英語です。
5. ここが質問なのですが、音声認識エンジンは何を使用するのがいいと言われているのでしょうか。ちょっとここをリサーチして僕に教えてください。

#### 🔍 音声認識エンジン リサーチ結果

Wispr Flow のようなデスクトップ向けリアルタイム音声入力アプリを構築するにあたり、主要な音声認識エンジンをリサーチしました。以下が比較結果です。

| エンジン | 種類 | リアルタイム対応 | 日本語/英語対応 | 精度 | コスト | 特徴 |
|---|---|---|---|---|---|---|
| **OpenAI Whisper (large-v3-turbo)** | ローカル（オープンソース） | △（追加実装が必要） | ◎ | ◎ 高精度 | 無料（GPU必要） | オフライン動作可、モデルをローカルで実行、日本語は最も精度が高い言語の一つ |
| **Deepgram** | クラウドAPI | ◎ 超低レイテンシ | ◎ | ◎ | 従量課金 | リアルタイムストリーミングに最適、WebSocket対応 |
| **Wispr Flow API** | クラウドAPI | ◎ | ◎（100言語以上） | ◎ | 要確認 | WebSocket/REST API、16kHz PCM WAV形式 |
| **Google Cloud Speech-to-Text** | クラウドAPI | ◎ | ◎（70言語以上） | ◎ | 従量課金 | Chirpモデルでアクセント対応に強い |
| **AssemblyAI** | クラウドAPI | ◎ | ○ | ◎ | 従量課金 | 感情分析やキーワード抽出などの付加機能あり |

**参考：Wispr Flow と SuperWhisper の技術的アプローチの違い**

- **Wispr Flow**: クラウドベースのAI処理に依存。インターネット接続が必要。コマンドモードによる音声編集機能あり。Mac/Windows/iOS対応。
- **SuperWhisper**: ローカル（オンデバイス）でのAI処理を重視。プライバシー優先。macOS/iOS対応。OpenAI、Deepgram、NVIDIA Parakeet等の複数モデルに対応。

**推奨候補（判断はお客様に委ねます）：**

1. **OpenAI Whisper (large-v3-turbo)** — 無料でオープンソース。日本語・英語の精度が高い。ただし、リアルタイムストリーミングには追加実装（VADチャンキング等）が必要。VRAM約6GB必要。
2. **Deepgram** — リアルタイムストリーミングに最も適したクラウドAPI。低レイテンシが必要な場合に最適。従量課金。
3. **Google Cloud Speech-to-Text** — 安定したクラウドAPI。多言語対応に強い。従量課金。

[Answer] 個人的にリサーチした結果、Apple Speech Analyzerの方がおすすめという意見があったんですけど、ここについてはどうでしょうか。

#### 🔍 Apple SpeechAnalyzer 追加リサーチ結果

Apple は WWDC 2025 で **SpeechAnalyzer** フレームワークを発表しました（従来の SFSpeechRecognizer の後継）。以下が詳細な比較です。

**Apple SpeechAnalyzer の特徴：**
- **完全オンデバイス処理**: 音声データをクラウドに送信せず、ローカルで処理。プライバシーが高い
- **無料**: Apple プラットフォーム上では追加コストなし
- **高速**: Whisper large-v3-turbo と比較して約3倍速い処理速度
- **リアルタイム対応**: `async/await` による非同期処理で、リアルタイム文字起こしに対応
- **日本語・英語対応**: 25言語以上に対応
- **長時間音声対応**: 従来の SFSpeechRecognizer の1分制限を克服
- **遠距離音声対応**: マイクから離れた話者の音声も認識可能

**Apple SpeechAnalyzer vs OpenAI Whisper 比較：**

| 項目 | Apple SpeechAnalyzer | OpenAI Whisper (large-v3-turbo) |
|---|---|---|
| **精度** | クリアな音声では高精度。ノイズ・アクセントには弱め | ノイズ・アクセント・多様な環境で最高精度 |
| **速度** | ◎ 約3倍高速 | △ やや遅い |
| **コスト** | 無料（macOS標準） | 無料（オープンソース、GPU必要） |
| **リアルタイム** | ◎ ネイティブ対応 | △ 追加実装が必要 |
| **オフライン** | ◎ 完全オンデバイス | ◎ ローカル実行可能 |
| **プライバシー** | ◎ データ送信なし | ◎ ローカル処理 |
| **プラットフォーム** | macOS/iOS のみ | クロスプラットフォーム |
| **カスタマイズ** | △ 限定的（語彙カスタマイズ） | ◎ オープンソースで自由 |

**総合評価：**
- **精度最優先** → OpenAI Whisper の方が一般的に高精度（特にノイズ環境やアクセント対応）
- **速度・手軽さ・コスト優先** → Apple SpeechAnalyzer の方が有利（macOS標準、追加実装不要、高速）
- **Wispr Flow レベルの精度** → Whisper の方が近い（Wispr Flow 自体がクラウドベースの高精度エンジンを使用）

今回の要件（デスクトップ Mac アプリ、日本語・英語、個人利用、コスト重視）を考慮すると、**両方とも無料**で利用可能です。

[Question] 以下の2つの選択肢からどちらを採用しますか？または両方を組み合わせるアプローチも可能です。
1. **Apple SpeechAnalyzer** — 速度が速く、macOS ネイティブで追加実装が少ない。ただし精度は Whisper にやや劣る場合がある
2. **OpenAI Whisper (large-v3-turbo)** — 精度が高い。ただしリアルタイム対応には追加実装が必要で、GPU(VRAM 6GB)が必要
3. **ハイブリッド** — Apple SpeechAnalyzer でリアルタイム表示し、Whisper で最終的な高精度補正を行う

[Answer]
Apple Speech Analyzerの方を採用して、その後GeminiのFlashlightなどでリライトすると精度がよくなるそうなので、そのハイブリッド版で行こうと思います。

---

### ステップ 2: ペルソナの定義

- [x] ユーザーストーリーで使用するペルソナ（ユーザー像）を定義する

[Question] 以下の点について教えてください：
1. 想定する主なユーザーペルソナはありますか？（例：忙しいビジネスパーソン、障がいのあるユーザー、外国語学習者 など）
2. ペルソナごとに異なるニーズや利用シナリオがありますか？

[Answer]
1. 特にペルソナは設定していません。
2. 特にありません。

---

### ステップ 3: 主要機能のリストアップ

- [x] アプリに必要な主要機能を洗い出す

[Question] 以下の機能のうち、必要なものはどれですか？また、その他に必要な機能はありますか？
1. リアルタイム音声認識（話しながらテキストに変換）
2. 音声ファイルのアップロードと文字起こし
3. テキストの編集・修正機能
4. テキストの保存・エクスポート機能
5. 話者の識別（複数人の会話を区別）
6. 句読点の自動挿入
7. 音声の録音機能
8. テキストの翻訳機能
9. 検索機能
10. 共有機能

[Answer]
まずは、リアルタイムで音声を認識して、その内容をテキストに変換する機能があればいいです。まずはそこだけでいいです。

---

### ステップ 4: 非機能要件の確認

- [x] パフォーマンス、セキュリティ、ユーザビリティなどの非機能要件を確認する

[Question] 以下の非機能要件について教えてください：
1. 音声認識の精度に関する期待値はありますか？
2. オフラインでの使用は必要ですか？
3. データのプライバシーやセキュリティに関する特別な要件はありますか？（例：音声データをサーバーに送信しない など）
4. 同時に利用するユーザー数の想定はありますか？
5. アクセシビリティに関する要件はありますか？

[Answer]
1. wispr flowと同じ精度でいきたいです。なので、ある程度精度は欲しいです。
2. オフラインでの使用は必要ではないです。
3. 今の段階ではありません。まずは個人用に作ろうと考えています。
4. 今のところありません。
5. 今のところありません。

---

### ステップ 5: ユーザーストーリーの作成

- [x] ステップ 1〜4 の回答に基づいて、ユーザーストーリーを作成する
- [x] 各ユーザーストーリーに受け入れ基準を定義する

---

### ステップ 6: ユーザーストーリーの優先順位付け

- [x] 作成したユーザーストーリーにMoSCoW法（Must/Should/Could/Won't）で優先順位を付ける

[Question] 優先順位付けの際に考慮すべきビジネス上の制約はありますか？（例：リリース期限、予算、開発リソース など）

[Answer]
予算だけですかね。
なるべくコストがかからないようにしたいです。

---

### ステップ 7: 最終レビューと承認

- [x] すべてのユーザーストーリーの最終レビューを実施する
- [x] 承認を得て、ユーザーストーリーを確定する

---

## 成果物

- `aidlc-docs/inception/user_stories.md` - 確定したユーザーストーリー一覧
