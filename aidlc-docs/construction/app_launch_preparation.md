# Whisper アプリ実行準備ガイド

実装済みの全3ユニットを実際に macOS アプリとして動かすために必要な準備事項をまとめます。

---

## 1. Xcode のインストール（必須・最大のブロッカー）

現在は `swift build`（Command Line Tools）でビルドしていますが、GUI アプリとして実行するには **Xcode** が必要です。

### 理由
- `MenuBarExtra` を持つ macOS アプリは**アプリバンドル（.app）**として実行する必要がある
- `Info.plist` にプライバシー権限記述を埋め込む必要がある
- コード署名（Code Signing）が必要
- ユニットテスト（`swift test`）の実行にも Xcode が必要

### 対応
- macOS 15.3.2 に対応する Xcode バージョンを確認しインストール
- Xcode プロジェクト（`.xcodeproj`）のセットアップ

---

## 2. Xcode プロジェクトのセットアップ

Xcode インストール後に必要な作業：

### Info.plist に追加する権限記述

| キー | 値（例） |
|---|---|
| `NSMicrophoneUsageDescription` | 「音声入力のためにマイクを使用します」 |
| `NSSpeechRecognitionUsageDescription` | 「音声をテキストに変換するために使用します」 |

### Entitlements（権限設定）

- App Sandbox を**無効化**（アクセシビリティ API の利用に必要）
- または必要な権限のみ個別に設定

---

## 3. OS レベルの権限付与（3つ）

アプリ起動後に以下の権限を付与する必要があります。

| 権限 | 用途 | 設定方法 |
|---|---|---|
| **マイクアクセス** | 音声キャプチャ（AVAudioEngine） | アプリ初回起動時にダイアログが自動表示 |
| **音声認識** | SFSpeechRecognizer | アプリ初回起動時にダイアログが自動表示 |
| **アクセシビリティ** | テキスト挿入（CGEvent でキーイベント発行） | **手動**: システム設定 > プライバシーとセキュリティ > アクセシビリティ で Whisper を許可 |

---

## 4. Gemini API キーの取得と設定

1. [Google AI Studio](https://aistudio.google.com/apikey) にアクセス
2. API キーを作成
3. Whisper アプリの **設定画面** で API キーを入力し「保存」
4. API キーは macOS Keychain に安全に保存される

> **Note**: API キーが未設定の場合でもアプリは動作します。リライト処理がスキップされ、音声認識の生テキストがそのまま出力されます。

---

## 5. ネットワーク接続

以下の機能にインターネット接続が必要です：

- **音声認識**（サーバー認識モード — Apple のサーバーに音声データを送信）
- **Gemini Flash API**（テキストリライト — Google のサーバーに認識テキストを送信）

---

## チェックリスト

- [ ] Xcode をインストール
- [ ] Xcode プロジェクトを作成し、Info.plist + Entitlements を設定
- [ ] アプリをビルド・起動
- [ ] マイクアクセス権限を許可
- [ ] 音声認識権限を許可
- [ ] アクセシビリティ権限を許可（システム設定から手動）
- [ ] Gemini API キーを取得し、設定画面で入力
- [ ] 動作確認: 音声入力 → リライト → テキスト出力
